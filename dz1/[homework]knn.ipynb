{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"[homework,adv]knn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"interpreter":{"hash":"eff37c55c47bac411226ca10e7fdee776304656b92d039d163cd589f68a386b5"}},"cells":[{"cell_type":"markdown","source":["<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" style=\"height:450px;\" width=500/></p>\n","\n","<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n","<h3 style=\"text-align: center;\"><b>Базовый и продвинутый потоки. Осень 2021</b></h3>\n","\n","<h1 style=\"text-align: center;\"><b>Домашнее задание. Библиотека sklearn и классификация с помощью KNN</b></h1>"],"metadata":{"id":"pgFYFftQKxY5"}},{"cell_type":"markdown","source":["На основе [курса по Машинному Обучению ФИВТ МФТИ](https://github.com/ml-mipt/ml-mipt) и [Открытого курса по Машинному Обучению](https://habr.com/ru/company/ods/blog/322626/)."],"metadata":{"id":"v4RCHGZULaWz"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"F2acNQu1L94J"}},{"cell_type":"markdown","source":["<h2 style=\"text-align: center;\"><b>K Nearest Neighbors (KNN)</b></h2>"],"metadata":{"id":"Twe_cnn5KxY6"}},{"cell_type":"markdown","source":["Метод ближайших соседей (k Nearest Neighbors, или kNN) — очень популярный метод классификации, также иногда используемый в задачах регрессии. Это один из самых понятных подходов к классификации. На уровне интуиции суть метода такова: посмотри на соседей; какие преобладают --- таков и ты. Формально основой метода является гипотеза компактности: если метрика расстояния между примерами введена достаточно удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных. "],"metadata":{"id":"YD0NXyUYKxY7"}},{"cell_type":"markdown","source":["<img src='https://hsto.org/web/68d/a45/6f0/68da456f00f8434e87628dbe7e3f54a7.png' width=600>"],"metadata":{"id":"CTa2jNZkKxY8"}},{"cell_type":"markdown","source":["\n","Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n","\n","* Вычислить расстояние до каждого из объектов обучающей выборки\n","* Отобрать объектов обучающей выборки, расстояние до которых минимально\n","* Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди $k$ ближайших соседей"],"metadata":{"id":"5H7wPU0IKxY-"}},{"cell_type":"markdown","source":["Будем работать с подвыборкой из [данных о типе лесного покрытия из репозитория UCI](http://archive.ics.uci.edu/ml/datasets/Covertype). Доступно 7 различных классов. Каждый объект описывается 54 признаками, 40 из которых являются бинарными. Описание данных доступно по ссылке."],"metadata":{"id":"T2docs4225pb"}},{"cell_type":"markdown","source":["### Обработка данных"],"metadata":{"id":"AcjJQX3wKxZA"}},{"cell_type":"code","execution_count":1,"source":["import pandas as pd\r\n","import numpy as np"],"outputs":[],"metadata":{"id":"Ozcx5mVOKxZB"}},{"cell_type":"markdown","source":["Сcылка на датасет (лежит в папке): https://drive.google.com/drive/folders/16TSz1P-oTF8iXSQ1xrt0r_VO35xKmUes?usp=sharing"],"metadata":{"id":"Ry4bMKaUjHJj"}},{"cell_type":"code","execution_count":2,"source":["all_data = pd.read_csv('forest_dataset.csv')\r\n","all_data.head()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2683</td>\n","      <td>333</td>\n","      <td>35</td>\n","      <td>30</td>\n","      <td>26</td>\n","      <td>2743</td>\n","      <td>121</td>\n","      <td>173</td>\n","      <td>179</td>\n","      <td>6572</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2915</td>\n","      <td>90</td>\n","      <td>8</td>\n","      <td>216</td>\n","      <td>11</td>\n","      <td>4433</td>\n","      <td>232</td>\n","      <td>228</td>\n","      <td>129</td>\n","      <td>4019</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2941</td>\n","      <td>162</td>\n","      <td>7</td>\n","      <td>698</td>\n","      <td>76</td>\n","      <td>2783</td>\n","      <td>227</td>\n","      <td>242</td>\n","      <td>148</td>\n","      <td>1784</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3096</td>\n","      <td>60</td>\n","      <td>17</td>\n","      <td>170</td>\n","      <td>3</td>\n","      <td>3303</td>\n","      <td>231</td>\n","      <td>202</td>\n","      <td>99</td>\n","      <td>5370</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2999</td>\n","      <td>66</td>\n","      <td>8</td>\n","      <td>488</td>\n","      <td>37</td>\n","      <td>1532</td>\n","      <td>228</td>\n","      <td>225</td>\n","      <td>131</td>\n","      <td>2290</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 55 columns</p>\n","</div>"],"text/plain":["      0    1   2    3   4     5    6    7    8     9  ...  45  46  47  48  49  \\\n","0  2683  333  35   30  26  2743  121  173  179  6572  ...   0   0   0   0   0   \n","1  2915   90   8  216  11  4433  232  228  129  4019  ...   0   0   0   0   0   \n","2  2941  162   7  698  76  2783  227  242  148  1784  ...   0   0   0   0   0   \n","3  3096   60  17  170   3  3303  231  202   99  5370  ...   0   0   0   0   0   \n","4  2999   66   8  488  37  1532  228  225  131  2290  ...   0   0   0   0   0   \n","\n","   50  51  52  53  54  \n","0   0   0   0   0   2  \n","1   0   0   0   0   1  \n","2   0   0   0   0   2  \n","3   0   0   0   0   1  \n","4   0   0   0   0   2  \n","\n","[5 rows x 55 columns]"]},"metadata":{},"execution_count":2}],"metadata":{"id":"rvPrVRvK25pc"}},{"cell_type":"code","execution_count":3,"source":["all_data.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 55)"]},"metadata":{},"execution_count":3}],"metadata":{"id":"_o8yXBPSKxZI"}},{"cell_type":"markdown","source":["Выделим значения метки класса в переменную `labels`, признаковые описания --- в переменную `feature_matrix`. Так как данные числовые и не имеют пропусков, переведем их в `numpy`-формат с помощью метода `.values`."],"metadata":{"id":"itCWxHEY25pg"}},{"cell_type":"code","execution_count":4,"source":["labels = all_data[all_data.columns[-1]].values\r\n","feature_matrix = all_data[all_data.columns[:-1]].values"],"outputs":[],"metadata":{"id":"f_YIUOuV25ph"}},{"cell_type":"code","execution_count":6,"source":["labels"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 1, 2, ..., 2, 2, 2], dtype=int64)"]},"metadata":{},"execution_count":6}],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["feature_matrix"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[2683,  333,   35, ...,    0,    0,    0],\n","       [2915,   90,    8, ...,    0,    0,    0],\n","       [2941,  162,    7, ...,    0,    0,    0],\n","       ...,\n","       [2693,   21,   11, ...,    0,    0,    0],\n","       [2536,   42,   11, ...,    0,    0,    0],\n","       [3109,  261,   10, ...,    0,    0,    0]], dtype=int64)"]},"metadata":{},"execution_count":7}],"metadata":{}},{"cell_type":"markdown","source":["### Пара слов о sklearn"],"metadata":{"id":"FukXaH_r8PMQ"}},{"cell_type":"markdown","source":["**[sklearn](https://scikit-learn.org/stable/index.html)** -- удобная библиотека для знакомства с машинным обучением. В ней реализованны большинство стандартных алгоритмов для построения моделей и работ с выборками. У неё есть подробная документация на английском, с которой вам придётся поработать."],"metadata":{"id":"k5S_0Lfc8PMR"}},{"cell_type":"markdown","source":["`sklearn` предпологает, что ваши выборки имеют вид пар $(X, y)$, где $X$ -- матрица признаков, $y$ -- вектор истинных значений целевой переменной, или просто $X$, если целевые переменные неизвестны."],"metadata":{"id":"VhVDEG538PMS"}},{"cell_type":"markdown","source":["Познакомимся со вспомогательной функцией \n","[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n","С её помощью можно разбить выборку на обучающую и тестовую части."],"metadata":{"id":"QJZQulsp8PMT"}},{"cell_type":"code","execution_count":8,"source":["from sklearn.model_selection import train_test_split"],"outputs":[],"metadata":{"id":"Q030jzyY25pl"}},{"cell_type":"markdown","source":["Вернёмся к датасету. Сейчас будем работать со всеми 7 типами покрытия (данные уже находятся в переменных `feature_matrix` и `labels`, если Вы их не переопределили). Разделим выборку на обучающую и тестовую с помощью метода `train_test_split`."],"metadata":{"id":"UkeB47mX8PMY"}},{"cell_type":"code","execution_count":9,"source":["train_feature_matrix, test_feature_matrix, train_labels, test_labels = train_test_split(\r\n","    feature_matrix, labels, test_size=0.2, random_state=42)"],"outputs":[],"metadata":{"id":"YJN0jFARKxZX"}},{"cell_type":"markdown","source":["Параметр `test_size` контролирует, какая часть выборки будет тестовой. Более подробно о нём можно прочитать в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."],"metadata":{"id":"odC1c7X48PMb"}},{"cell_type":"markdown","source":["Основные объекты `sklearn` -- так называемые `estimators`, что можно перевести как *оценщики*, но не стоит, так как по сути это *модели*. Они делятся на **классификаторы** и **регрессоры**.\n","\n","В качестве примера модели можно привести классификаторы\n","[метод ближайших соседей](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) и \n","[логистическую регрессию](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Что такое логистическая регрессия и как она работает сейчас не важно."],"metadata":{"id":"z3fGvPqG8PMc"}},{"cell_type":"markdown","source":["У всех моделей в `sklearn` обязательно должно быть хотя бы 2 метода (подробнее о методах и классах в python будет в следующих занятиях) -- `fit` и `predict`."],"metadata":{"id":"IuX8Rc7c8PMd"}},{"cell_type":"markdown","source":["Метод `fit(X, y)` отвечает за обучение модели и принимает на вход обучающую выборку в виде *матрицы признаков* $X$ и *вектора ответов* $y$.\n","\n","У обученной после `fit` модели теперь можно вызывать метод `predict(X)`, который вернёт предсказания этой модели на всех объектах из матрицы $X$ в виде вектора.\n","\n","Вызывать `fit` у одной и той же модели можно несколько раз, каждый раз она будет обучаться заново на переданном наборе данных.\n","\n","Ещё у моделей есть *гиперпараметры*, которые обычно задаются при создании модели.\n","\n","Рассмотрим всё это на примере логистической регрессии."],"metadata":{"id":"ZYokUkxO8PMe"}},{"cell_type":"code","execution_count":10,"source":["from sklearn.linear_model import LogisticRegression"],"outputs":[],"metadata":{"id":"ew0Ji_2D8PMe"}},{"cell_type":"code","execution_count":11,"source":["# создание модели с указанием гиперпараметра C\r\n","clf = LogisticRegression(C=1)\r\n","# обучение модели\r\n","clf.fit(train_feature_matrix, train_labels)\r\n","# предсказание на тестовой выборке\r\n","y_pred = clf.predict(test_feature_matrix)"],"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\LaughingMan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"metadata":{"id":"c9KcMHXr8PMh"}},{"cell_type":"markdown","source":["Теперь хотелось бы измерить качество нашей модели. Для этого можно использовать метод `score(X, y)`, который посчитает какую-то функцию ошибки на выборке $X, y$, но какую конкретно уже зависит от модели. Также можно использовать одну из функций модуля `metrics`, например [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), которая, как понятно из названия, вычислит нам точность предсказаний."],"metadata":{"id":"h3gjg3pm8PMm"}},{"cell_type":"code","execution_count":14,"source":["from sklearn.metrics import accuracy_score\r\n","\r\n","accuracy_score(test_labels, y_pred)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6075"]},"metadata":{},"execution_count":14}],"metadata":{"id":"J2Ej1Lni8PMn"}},{"cell_type":"markdown","source":["Наконец, последним, о чём хотелось бы упомянуть, будет перебор гиперпараметров по сетке. Так как у моделей есть много гиперпараметров, которые можно изменять, и от этих гиперпараметров существенно зависит качество модели, хотелось бы найти наилучшие в этом смысле параметры. Самый простой способ это сделать -- просто перебрать все возможные варианты в разумных пределах.\n","\n","Сделать это можно с помощью класса [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), который осуществляет поиск (search) по сетке (grid) и вычисляет качество модели с помощью кросс-валидации (CV).\n","\n","У логистической регрессии, например, можно поменять параметры `C` и `penalty`. Сделаем это. Учтите, что поиск может занять долгое время. Смысл параметров смотрите в документации."],"metadata":{"id":"malIDW_P8PMp"}},{"cell_type":"code","execution_count":15,"source":["from sklearn.model_selection import GridSearchCV"],"outputs":[],"metadata":{"id":"vq687Aoc8PMq"}},{"cell_type":"code","execution_count":16,"source":["# заново создадим модель, указав солвер\r\n","clf = LogisticRegression(solver='saga')\r\n","\r\n","# опишем сетку, по которой будем искать\r\n","param_grid = {\r\n","    'C': np.arange(1, 5), # также можно указать обычный массив, [1, 2, 3, 4]\r\n","    'penalty': ['l1', 'l2'],\r\n","}\r\n","\r\n","# создадим объект GridSearchCV\r\n","search = GridSearchCV(clf, param_grid, n_jobs=-1, cv=5, refit=True, scoring='accuracy')\r\n","\r\n","# запустим поиск\r\n","search.fit(feature_matrix, labels)\r\n","\r\n","# выведем наилучшие параметры\r\n","print(search.best_params_)"],"outputs":[{"output_type":"stream","name":"stdout","text":["{'C': 2, 'penalty': 'l2'}\n"]},{"output_type":"stream","name":"stderr","text":["C:\\Users\\LaughingMan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\"The max_iter was reached which means \"\n"]}],"metadata":{"id":"OVnqHBvK8PMs"}},{"cell_type":"code","execution_count":35,"source":["search.get_params().keys()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['cv', 'error_score', 'estimator__C', 'estimator__class_weight', 'estimator__dual', 'estimator__fit_intercept', 'estimator__intercept_scaling', 'estimator__l1_ratio', 'estimator__max_iter', 'estimator__multi_class', 'estimator__n_jobs', 'estimator__penalty', 'estimator__random_state', 'estimator__solver', 'estimator__tol', 'estimator__verbose', 'estimator__warm_start', 'estimator', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])"]},"metadata":{},"execution_count":35}],"metadata":{}},{"cell_type":"markdown","source":["В данном случае, поиск перебирает все возможные пары значений C и penalty из заданных множеств."],"metadata":{"id":"DnVTFcvZ8PMv"}},{"cell_type":"code","execution_count":17,"source":["accuracy_score(labels, search.best_estimator_.predict(feature_matrix))"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6416"]},"metadata":{},"execution_count":17}],"metadata":{"id":"ArKINrE_8PMw"}},{"cell_type":"markdown","source":["Заметьте, что мы передаём в GridSearchCV всю выборку, а не только её обучающую часть. Это можно делать, так как поиск всё равно использует кроссвалидацию. Однако порой от выборки всё-же отделяют *валидационную* часть, так как гиперпараметры в процессе поиска могли переобучиться под выборку."],"metadata":{"id":"okzpKY_I8PMz"}},{"cell_type":"markdown","source":["В заданиях вам предстоит повторить это для метода ближайших соседей."],"metadata":{"id":"_mdJyxdo8PM1"}},{"cell_type":"markdown","source":["### Обучение модели"],"metadata":{"id":"z8W__017KxZc"}},{"cell_type":"markdown","source":["Качество классификации/регрессии методом ближайших соседей зависит от нескольких параметров:\n","\n","* число соседей `n_neighbors`\n","* метрика расстояния между объектами `metric`\n","* веса соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его \"голос\") `weights`\n"],"metadata":{"id":"02uT6CPYKxZe"}},{"cell_type":"markdown","source":["Обучите на датасете `KNeighborsClassifier` из `sklearn`."],"metadata":{"id":"BHVNCaJ325qD"}},{"cell_type":"code","execution_count":37,"source":["from sklearn.neighbors import KNeighborsClassifier\r\n","from sklearn.metrics import accuracy_score\r\n","\r\n","k_clf = KNeighborsClassifier()\r\n","k_clf.fit(train_feature_matrix, train_labels)\r\n","y_pred = k_clf.predict(test_feature_matrix)\r\n","\r\n","# Ваш код здесь"],"outputs":[],"metadata":{"id":"o4CMnnOY25qD"}},{"cell_type":"code","execution_count":38,"source":["accuracy_score(test_labels, y_pred)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7365"]},"metadata":{},"execution_count":38}],"metadata":{}},{"cell_type":"markdown","source":["### Вопрос 1:\n","* Какое качество у вас получилось?"],"metadata":{"id":"r_2Mf8BiKxZk"}},{"cell_type":"markdown","source":["Подберём параметры нашей модели"],"metadata":{"id":"uFTIaPdrKxZl"}},{"cell_type":"markdown","source":["* Переберите по сетке от `1` до `10` параметр числа соседей\n","\n","* Также вы попробуйте использоввать различные метрики: `['manhattan', 'euclidean']`\n","\n","* Попробуйте использовать различные стратегии вычисления весов: `[‘uniform’, ‘distance’]`"],"metadata":{"id":"8WzoRJZd25qF"}},{"cell_type":"code","execution_count":41,"source":["from sklearn.model_selection import GridSearchCV\r\n","params = {\r\n","    'n_neighbors' : np.arange(1, 11),\r\n","    'metric' : ['manhattan', 'euclidean'],\r\n","    'weights' : ['uniform', 'distance']\r\n","}\r\n","\r\n","clf_grid = GridSearchCV(k_clf, params, cv=5, n_jobs=-1)\r\n","clf_grid.fit(feature_matrix, labels)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n","             param_grid={'metric': ['manhattan', 'euclidean'],\n","                         'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n","                         'weights': ['uniform', 'distance']})"]},"metadata":{},"execution_count":41}],"metadata":{"id":"4lMSy-6f25qG","scrolled":true}},{"cell_type":"code","execution_count":30,"source":["clf_grid.get_params().keys()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['cv', 'error_score', 'estimator__algorithm', 'estimator__leaf_size', 'estimator__metric', 'estimator__metric_params', 'estimator__n_jobs', 'estimator__n_neighbors', 'estimator__p', 'estimator__weights', 'estimator', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])"]},"metadata":{},"execution_count":30}],"metadata":{}},{"cell_type":"markdown","source":["Выведем лучшие параметры"],"metadata":{"id":"SO7E6G8jKxZp"}},{"cell_type":"code","execution_count":42,"source":["clf_grid.best_params_"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}"]},"metadata":{},"execution_count":42}],"metadata":{"id":"md48pHrMKxZq"}},{"cell_type":"markdown","source":["### Вопрос 2:\n","* Какую metric следует использовать?"],"metadata":{"id":"M05n9l8pKxZt"}},{"cell_type":"markdown","source":["### Вопрос 3:\n","* Сколько n_neighbors следует использовать?"],"metadata":{"id":"Pmjx38OoKxZt"}},{"cell_type":"markdown","source":["### Вопрос 4:\n","* Какой тип weights следует использовать?"],"metadata":{"id":"eqLeJUP8KxZu"}},{"cell_type":"markdown","source":["Используя найденное оптимальное число соседей, вычислите вероятности принадлежности к классам для тестовой выборки (`.predict_proba`)."],"metadata":{"id":"aBmiDbvV25qI"}},{"cell_type":"code","execution_count":47,"source":["optimal_clf = KNeighborsClassifier(n_neighbors=4)\r\n","optimal_clf.fit(train_feature_matrix, train_labels)\r\n","pred_prob = optimal_clf.predict_proba(test_feature_matrix)"],"outputs":[],"metadata":{"id":"ig_vS8O925qI"}},{"cell_type":"code","execution_count":48,"source":["print(pred_prob[:, 2].mean())"],"outputs":[{"output_type":"stream","name":"stdout","text":["0.05325\n"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\r\n","%matplotlib inline\r\n","import numpy as np\r\n","\r\n","unique, freq = np.unique(test_labels, return_counts=True)\r\n","freq = list(map(lambda x: x / len(test_labels),freq))\r\n","\r\n","pred_freq = pred_prob.mean(axis=0)\r\n","plt.figure(figsize=(10, 8))\r\n","plt.bar(range(1, 8), pred_freq, width=0.4, align=\"edge\", label='prediction')\r\n","plt.bar(range(1, 8), freq, width=-0.4, align=\"edge\", label='real')\r\n","plt.ylim(0, 0.54)\r\n","plt.legend()\r\n","plt.show()"],"outputs":[],"metadata":{"id":"2kkapT38KxZz"}},{"cell_type":"markdown","source":["### Вопрос 5:\n","* Какая прогнозируемая вероятность pred_freq класса под номером 3 (до 2 знаков после запятой)?"],"metadata":{"id":"gp4uDyLmKxZ3"}}]}